# Regularization and Optimization

## The solution for bias and varance

**If bias:**

- Bigger network (deeper or bigger layer)
- Train longer
- Find neuro network architecture

**If variance:**

- More training data
- Regularization 
- Find neuro network architecture

## Regularization

1. **L2 regularization**
   - <img src="https://latex.codecogs.com/png.latex?J(w,&space;b)&space;=&space;\cfrac{1}{m}&space;\sum_{i&space;=&space;1}^{m}L(\widehat{y}^{(i)},&space;y^{(i)})&plus;\frac{\lambda}{2m}b^{2}" title="J(w, b) = \cfrac{1}{m} \sum_{i = 1}^{m}L(\widehat{y}^{(i)}, y^{(i)})+\frac{\lambda}{2m}b^{2}" />
2. **Dropout regularization**


